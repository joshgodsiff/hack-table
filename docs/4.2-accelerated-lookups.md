# 4.2 Accelerated Lookups

Another optimization in the implementation is to achieve fewer hops per lookup by increasing the routing table size. Conceptually, this is done by considering b bits at a time instead of just one bit at a time. As previously described, the expected number of hops per lookup is log₂ n. By increasing the routing table's size to an expected 2ᵇlog₂ n k-buckets, we can reduce the number of expected hops to log₂ᵇ n.

Section 2.4 describes how a Kademlia node splits a k-bucket when the bucket is full and its range includes the node's own ID. The implementation, however, also splits ranges not containing the node's ID, up to b - 1 levels. If b = 2, for instance, the half of the ID space not containing the node's ID gets split once (into two ranges); if b = 3, it gets split at two levels into a maximum of four ranges, etc. The general splitting rule is that a node splits a full k-bucket if the bucket's range contains the node's own ID or the depth d of the k-bucket in the routing tree satisfies d ≡ 0 (mod b). (The depth is just the length of the prefix shared by all nodes in the k-bucket's range.) The current implementation uses b = 5.

Though XOR-based routing resembles the first stage routing algorithms of Pastry[1], Tapestry[2], and Plaxton's distributed search algorithm[3], all three become more complicated when generalized to b > 1. Without the XOR topology, there is a need for an additional algorithmic structure for discovering the target within the nodes that share the same prefix but differ in the next b-bit digit. All three algorithms resolve this problem in different ways, each with its own drawbacks: they all require secondary routing tables of size O(2ᵇ) in addition to the main tables of size O(2ᵇlog₂ᵇ n). This increases the cost of bootstrapping and maintenance, complicates the protocols, and for Pastry and Tapestry complicates or prevents a formal analysis of correctness and consistency. Plaxton has a proof, but the system is less geared for highly fault-prone environments like peer-to-peer networks.